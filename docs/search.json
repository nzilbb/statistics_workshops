[
  {
    "objectID": "getting_started.html#install-r-and-rstudio",
    "href": "getting_started.html#install-r-and-rstudio",
    "title": "1Â  Getting Started",
    "section": "",
    "text": "Windows: open the â€œSoftware Centerâ€, search for RStudio, and press the install button.\nMac: open â€œUC Self Serviceâ€, search for RStudio, and press the install button.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#open-rstudio",
    "href": "getting_started.html#open-rstudio",
    "title": "1Â  Getting Started",
    "section": "1.2 Open RStudio",
    "text": "1.2 Open RStudio\nIf you have installed RStudio, if should now appear in your start menu on Windows, and your Applications folder and launchpad if you are on macOS. Open it. You should see something like this:\n\n\nThe RStudio interface has four primary â€˜panesâ€™. Only three of these will be visible when you first open RStudio. The largest pane is the console pane. It is usually on the bottom left of the RStudio window, but currently takes up the entire left side. We also see the environment pane at the top right and the output pane at the bottom right.2\nThe console pane should have a message telling you what version of R you are using and the platform you are on (i.e.Â your hardware and operating system). This is what you would see if you opened R by itself.3\nThe environment pane should be empty. You will see multiple tabs across the top of this pane. The environment tab will allow us to see the data which we are working with at a given time. At this stage, you may see a tab labelled â€˜Tutorialâ€™. Iâ€™ll tell you how to use this later (Section 1.6).\nThe output pane will start by showing you a list of files on your computer. This is useful for finding and manipulating files (just like a file browser) In future, it is also where plots and help pages will appear.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#interact-with-r-in-the-console",
    "href": "getting_started.html#interact-with-r-in-the-console",
    "title": "1Â  Getting Started",
    "section": "1.3 Interact with R in the Console",
    "text": "1.3 Interact with R in the Console\nWe will get started by interacting with R in the console pane. You should see a &gt; in the console pane. We can enter code here. If the code works, we will see the output immediately below (or perhaps in the output pane, depending on the code). If the code doesnâ€™t work, an error message will appear.\n\n1.3.1 Basic arithmetic\nWeâ€™ll start with some basic arithmetic. We add two numbers together by writing the first number, the + sign, and the second number. Enter the code in the box below after the &gt; in your console. The expected output appears below the box. You should see the same thing in your console after you press enter/return.\n\n1 + 1\n\n[1] 2\n\n\nThe other basic arithmetic operators work in the same way. Subtraction:\n\n500 - 49\n\n[1] 451\n\n\nWe use * for multiplication. We enter real numbers by using a decimal point.\n\n43 * 6.4\n\n[1] 275.2\n\n\nFor exponentiation we use ^ (usually, shift + 6).\n\n924^5\n\n[1] 6.735345e+14\n\n\nThe output given here is in scientific notation. It is important to be able to read this notation when using R. It makes very very small and very very large numbers much easier to write and is often used in the output of R functions. To convert from scientific notation to regular digits, multiple the number which appears before the e by 10 to the power of the number after the e. In this case, we take the number \\(6.735345\\) and multiply it by \\(10^{14}\\) to get \\(673,534,500,000,000\\). That is, six hundred seventy-three trillion and a bit. According to Wikipedia, this is something like the total number of cells in six and a half adult humans and a bit fewer than the number of ants on Earth.\nThere are a few different operators associated with division. Usually, you will want to use /. e.g.:\n\n43 / 7\n\n[1] 6.142857\n\n\nSometimes, it is useful to get the integer component on the answer or the remainder. If we want the integer, we use %/%:\n\n43 %/% 7\n\n[1] 6\n\n\nIf we want the remainder, we use:\n\n43 %% 7\n\n[1] 1\n\n\nThat is, if we divide 43 by 7, we get 6 groups of 7, with 1 remaining.\nComputer programming requires attention to minor details of punctuation and spacing. Hours can be spent trying to discover why code is not working, only to discover a missing comma. This is especially true in the early stages of learning, where error messages can be very confusing.\nIt is worth knowing when you can add spaces and when you canâ€™t. The spaces in the code above between the numbers and the arithmetic operators are not necessary. So, for instance, you could write:\n\n43/7\n\n[1] 6.142857\n\n\nIn fact, you can add however many spaces you like!\n\n34  /    2\n\n[1] 17\n\n\nThe only reason to prefer one over the other is readability. This raises the issue of code style, which we will discuss in future workshops. Note that, above, there wasnâ€™t a space in 924^5â€”this is a style convention for ^ and some other (â€˜high precedenceâ€™) operators which we will encounter later.4\n\n\n1.3.2 Vectors and Variables\nWe work with large collections of experimental data or values derived from corpora. But the commands weâ€™ve looked at above only deal with two numbers at a time. The simplest structure for dealing with more than one value is a vector.\nWe create vectors using the function c(). The c() function combines values in to a vector.\n\nc(1, 2, 3, 4)\n\n[1] 1 2 3 4\n\n\nThe [1] you see in the output is followed by the first element of the vector. If you print out a very long vector you will see numbers other than 1 inside the square brackets. For instance:\n\n60:124\n\n [1]  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n[20]  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97\n[39]  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n[58] 117 118 119 120 121 122 123 124\n\n\nThe : operator produces a vector from the first number to the second number (inclusive) in steps of one. The resulting output is long enough that it has to go across two lines. When the new line starts you will see another number in square brackets. This tells you how far through the vector you are at the line break. Exactly which number it is will vary according to the system you are using. For me, currently editing this text in RStudio, it is [38]. That is, the number which follows [38] is the 38th number in the vector.\nWe call the values in a vector the elements of the vector. The elements of a vector have to be the same type of thing. Weâ€™ll talk about types more later. For now, just note that a number is a different kind of thing from a string of characters. So, what happens if we try to mix numbers and strings in a vector?\n\nc(1, 2, 3, \"dog\")\n\n[1] \"1\"   \"2\"   \"3\"   \"dog\"\n\n\nR hasnâ€™t explicitly complained, but it has done something without telling you what it has done. The numbers we entered now have quotation marks around them. They have been turned in to strings. Keep an eye out for quotation marks â€” sometimes you might think you are dealing with numbers, but really you are dealing with strings. This is a common problem when loading your own data.\nWhy worry? Well, your code likely wonâ€™t work if you have strings rather than numbers. For instance, you canâ€™t apply arithmetic operators to strings.\n\n\"1\" + \"2\"\n\nError in \"1\" + \"2\": non-numeric argument to binary operator\n\n\nThe above is the first error message youâ€™ve seen in this course. You will see many more in your time working with R. The error message is telling you that what you are doing does not work on anything but numbers.\nTo enter a string, you can use either double quotes or single quotes.\nVectors can also be used for arithmetic. Under the hood, statistics is mostly arithmetic with collections of vectors. How are these arithmetic operations implemented in R?\nThe simplest case is when we use a vector and a single number, as follows\n\n2 * c(1, 2, 3, 4)\n\n[1] 2 4 6 8\n\n\nEach element of the vector has been multiplied by \\(2\\). The same is true of addition, division, and subtraction. These are â€˜element-wiseâ€™ operations. That is, they are applied to each element individually.\n\n3 / c(1, 2, 3, 4)\n\n[1] 3.00 1.50 1.00 0.75\n\n\nThis also works with two vectors. For instance:\n\nc(1, 2, 3, 4) * c(1, 2, 3, 4)\n\n[1]  1  4  9 16\n\n\nHere we get the first elements multiplied together, then the second, then the third, and so on.\nIf one vector is shorter than the other, is will be â€˜recycledâ€™ to match the longer vector:\n\nc(1, 2) * c(1, 2, 3, 4)\n\n[1] 1 4 3 8\n\n\nYou do not want to be entering the same vector over and over again. This is where variables come in. Variables allow us to associate names with values.\nTo assign an object to a name, we use &lt;-. For instance:\n\nmy_cool_vector &lt;- c(6, 9, 4, 5, 2, 2)\n\nNow the name my_cool_vector is associated with the vector c(6, 9, 4, 5, 2, 2). If you look to the top right of the RStudio window you should now see this variable in your environment pane. The name will be on the left and the value on the right.\n\n\n\nOur cool vector in the RStudio environment pane. Your screen may look a little different.\n\n\n\n\n\n\n\n\nWarning\n\n\n\nIn most cases you can also use = to assign an object to a name. This may seem more natural to you if you are coming from another programming languages. The convention is to use &lt;-. Sometimes = takes on a different function, but &lt;- is always assignment of an object to a name.\n\n\nWe can now apply operations using the name. For instance:\n\n4 * my_cool_vector\n\n[1] 24 36 16 20  8  8\n\n\nTo see what object is associated with a name we can look in the environment pane or simply enter the name into the console.\n\nmy_cool_vector\n\n[1] 6 9 4 5 2 2\n\n\nWe can also look up specific elements using square brackets. If we wanted to look up the fourth element in my_cool_vector we would enter the following code.\n\nmy_cool_vector[4]\n\n[1] 5\n\n\nWe can even change elements by using the assignment opperator (&lt;-).\n\nmy_cool_vector[4] &lt;- 3\nmy_cool_vector\n\n[1] 6 9 4 3 2 2\n\n\nThe fourth entry in the vector is now 3 rather than 5.\nNaming variables is serious business. It is important to know what you could do and what you should do.\nR institutes the following rules for names:\n\nA name must consist of letters, digits, ., and _.\nIt cannot begin with digits or _.\nIt cannot come from a list of reserved words (e.g.Â TRUE â€” these names have important roles in R and canâ€™t be overridden.)\n\n\n\n\n\n\n\nNote\n\n\n\nWhat counts as a â€˜letterâ€™ varies by operating system and local settings (your â€˜localeâ€™). The recommendation from Hadley Wickham is that you only use ASCII letters (for instance, avoid use of any diacritics/accents).5\nOne local reason you might want to use non-ASCII characters is if you want to use te reo MÄori with macrons for your variable names. This might be appropriate for a particular project (the question is always who you want to share your code with). Pretty much anyone using a modern operating system should be able to use your code. You may decide that the small risk of incompatibility is worth it in this case.\n\n\nI follow the convention of using _ rather than . in my variable names. So, e.g., Iâ€™d prefer my_cool_vector over my.cool.vector. This reduces ambiguity in some cases.\nWhile we are talking about naming, R will accept anything placed within backticks (â€˜`â€™) as a variable name. If you have a chaotic temperament, you might decide to use variable names like this:\n\n# Eldritch variable\n`tÌ¸Ì¡ÍšÌ³Í“ÌœÌ˜ÌªÌ™ÌŸÌ£Í›Ì‹ÌˆÌÍœá¸©Ì·Ì›Ì—Ì¬ÌªÌ”Ì¾Í‹ÌŒÌ‚Ì“Í‘Ì”ÌšÍÃ«ÌµÌ®ÌŸÌŸÌ¼Ì²Ì¦Í™Ì ÌŸÌÍ‹Ì‡ÌÌ“ Ì¶ÌŸÌ±Ì²Ì ÍÌ™Ì Ì†Ì‘ÌˆÌÌ‰Ì†ÌÌ‹Í Í tÌ·Ì²Í‰Í”Ì˜Ì¬ÌªÍ–Ì—ÌÍŒÌÌ‰ÌÌ„ÍŠÌÌ½Í‹ÌˆÌˆÌÌ€ÍÍ oÌµÍšÍ™Ì®Í™Í‰Ì±Ì±Í•Ì—Ì˜Ì»Í‹Í‹Í‹Ì€ÌÌ’ÍÍ…wÌ¸Í–ÍšÌ–Ì£Ì­Ì¥ÍÌ¹ÍšÌÍ•ÌºÍ‡Í™ÍŒÍ›Í‹Ì†Ì¿ÌˆÌÌÌ†Ì‹Ì‘ÍŒÌÍ˜Í ÍeÌµÍ–ÌÌÌ™Í•Ì¤Ì…ÌƒÌ“rÌ´ÍÌ¼Ì±ÌœÌ¹ÍšÌÌŒÌ‚Í†Í—ÌÌá¹¡Ì·Í”Í‰Í‡Í—ÌÌ†Ì”Ì•Í… Ì·ÌªÌ±ÌÍˆÌ°ÌˆÌÍœÇ«Ì·Ì¤ÍÌ«Ì Ì»Ì£ÌªÌ»Í–Ì’ÌˆÌÍÍ‚Ì¿Ì†Ì‘Ì„Ì‚Í˜fÌ¶Ì Í‰Ì¯ÌªÌªÌ–Ì¦Í‹Í Ì¶Ì™Ì»ÌÍ†ÌˆÍ CÌ´Ì³ÌªÌªÌ»Ì«Ì¬Ì³ÌœÌ…Í‘Ì‡ÍŒÌ†Ì•aÌ¶Ì¡ÍšÌ¼ÍÌºÍ‚ÌˆÌÌ„rÌ·Ì¨Ì›Ì›ÌœÌ¹Í™Ì²ÌÌ²Ì–ÍÌ“ÌŠÍ’Ì„Ì“ÌÍ‚ÍÍ›Í‘ÌŠÍ˜cÌ¸Í‡Ì²Ì²ÍˆÍ•Í‰ÍÌ—ÌÆ¡ÌµÌŸÌ Ì’Ì”Í‘Í†sÌ¶Ì¨Ì¢Ì±Ì±Ì²Í‡Í‰ÌªÌ»Ì–Ì ÍŠÌˆÌÌÍ‹ÌÌˆÌÍœaÌ¸Ì—Ì©Ì¯Ì³ÌÍˆÌ°Ì…Í’Ì‚ÌÍ›Ì½Ì“Í‘ÌˆÌÌ¾Í… Ì·Ì¢ÍÍÌ³Ì–Ì¤Ì¥ÌœÌ€Ì‘ÌˆÌÌˆÌrÌ´Ì¦ÍŒÍ›Í˜oÌ´Ì©Ì©Ì¯Ì¤ÌÌŠÍ—Ì¿Ì‰Í—Í‚Í‚Ì†ÌˆÌÍ˜sÌ¶Í”Ì¼ÌÌ±Ì»Ì­Ì»Í‘Ì”Í›Ì”á¸™Ì¸Ì¢Ì€ÌÍ—Ì“ÍŠÌˆÌŠÌ‰ÌšÌšÍ Ì¸Ì Ì°ÌÌ¬ÌÌ†Ì½Ì…Ì€ÌˆÌ‚ÌŒÍ bÌ¶Ì§ÌœÌŸÍÍ”Ì˜Ì¥Í‡ÌˆÌÍ’ÌƒÍ’ÌˆÌÍŠÌ“Ì‰ÌÌ‰ÌÍ˜Í˜ÍÍÄ™ÌµÍšÌ€ÌˆÌÌ¿ÌŒÌ†ÌˆÌÍ˜Ì•Í ÍÍ…hÌ¸Ì›ÍÌ±ÍšÍ•Ì¹Ì˜Ì¥Ì Í•ÌŸÌ¼ÍÍ…Ã®Ì¶ÌÌ¹ÌºÌ°ÌÌ¿ÌŠÌ½Í’Í‘Í‘Ì½ÍnÌµÌ¢Ì¢Ì›Ì›ÌŸÍ“Ì—Ì®Ì¦ÌªÌ¥Ì©Í“ÌªÌ˜Í—Í—Ì‘ÌŠÌŒÌ‰Ì‚ÍŠÍ ÍdÌµÍÌ­Ì¤Ì²Í‹ÍŒÌƒÌÌŠ Ì·Ì§Ì§Ì›Ì¤Í‡Ì«ÌÌ—Ì»ÍšÌÌŠÌˆÌÌ‡Ì‚Í—Ì‹tÌµÍ“Ì»Ì¦Ì»Ì—Í‡ÌœÌ¼Ì»Ì«Ì¼Ì­Ì„ÌÍ˜ÌšhÌµÌ¨Ì…Ì‰Ì„eÌ¸Ì¡Ì¡Ì¨ÌÌªÌÌÌŸÍ”ÌÌÍ”Ì°Ì’Ì“Í†ÌÍ›Ì‚Ì’Í‚ÌŠÌ†Ì½ÌƒÌŒÍ˜ Ì´Ì›Ì¦Ì–Ì–Ì–Ì¹Ì–Ì¹Ì£Ì³Ì•mÌ¶Ì¡Í‰Ì¦Ì£Í‰Ì³ÌªÍ–Í•ÍÍ™ÌªÌŸÍŒÌÌÍ†ÌÌ„Ì‚ÌšÍ˜oÌ¸Ì­Ì¯Ì Ì­ÍÌ–ÍÍ—ÌÌ‰Í‹Ì…ÍŠÌ“Ì“Ì‚ÌÌ“ÌÌÍÇ«Ì´Í–ÍˆÌ–Ì£Ì¤ÍÌÌ©Ì³ÌªÌ”Í‚Ì‹Ì„Ì‘ÌÌ’ÌÌÌˆÌÃ±Ì¸Ì™ÌªÍ‰Í“Ì¼Ì¯Ì©Í‹Ì‹ÌŒÌÌƒÍ˜Ì•Í˜.ÌµÌ™Ì®Ì¾ÌÍ Í…` &lt;- 10\n\n# Spooky variable\n`ğŸ‘»` &lt;- 5\n\nAnd you could even do some maths with these variables:\n\n`tÌ¸Ì¡ÍšÌ³Í“ÌœÌ˜ÌªÌ™ÌŸÌ£Í›Ì‹ÌˆÌÍœá¸©Ì·Ì›Ì—Ì¬ÌªÌ”Ì¾Í‹ÌŒÌ‚Ì“Í‘Ì”ÌšÍÃ«ÌµÌ®ÌŸÌŸÌ¼Ì²Ì¦Í™Ì ÌŸÌÍ‹Ì‡ÌÌ“ Ì¶ÌŸÌ±Ì²Ì ÍÌ™Ì Ì†Ì‘ÌˆÌÌ‰Ì†ÌÌ‹Í Í tÌ·Ì²Í‰Í”Ì˜Ì¬ÌªÍ–Ì—ÌÍŒÌÌ‰ÌÌ„ÍŠÌÌ½Í‹ÌˆÌˆÌÌ€ÍÍ oÌµÍšÍ™Ì®Í™Í‰Ì±Ì±Í•Ì—Ì˜Ì»Í‹Í‹Í‹Ì€ÌÌ’ÍÍ…wÌ¸Í–ÍšÌ–Ì£Ì­Ì¥ÍÌ¹ÍšÌÍ•ÌºÍ‡Í™ÍŒÍ›Í‹Ì†Ì¿ÌˆÌÌÌ†Ì‹Ì‘ÍŒÌÍ˜Í ÍeÌµÍ–ÌÌÌ™Í•Ì¤Ì…ÌƒÌ“rÌ´ÍÌ¼Ì±ÌœÌ¹ÍšÌÌŒÌ‚Í†Í—ÌÌá¹¡Ì·Í”Í‰Í‡Í—ÌÌ†Ì”Ì•Í… Ì·ÌªÌ±ÌÍˆÌ°ÌˆÌÍœÇ«Ì·Ì¤ÍÌ«Ì Ì»Ì£ÌªÌ»Í–Ì’ÌˆÌÍÍ‚Ì¿Ì†Ì‘Ì„Ì‚Í˜fÌ¶Ì Í‰Ì¯ÌªÌªÌ–Ì¦Í‹Í Ì¶Ì™Ì»ÌÍ†ÌˆÍ CÌ´Ì³ÌªÌªÌ»Ì«Ì¬Ì³ÌœÌ…Í‘Ì‡ÍŒÌ†Ì•aÌ¶Ì¡ÍšÌ¼ÍÌºÍ‚ÌˆÌÌ„rÌ·Ì¨Ì›Ì›ÌœÌ¹Í™Ì²ÌÌ²Ì–ÍÌ“ÌŠÍ’Ì„Ì“ÌÍ‚ÍÍ›Í‘ÌŠÍ˜cÌ¸Í‡Ì²Ì²ÍˆÍ•Í‰ÍÌ—ÌÆ¡ÌµÌŸÌ Ì’Ì”Í‘Í†sÌ¶Ì¨Ì¢Ì±Ì±Ì²Í‡Í‰ÌªÌ»Ì–Ì ÍŠÌˆÌÌÍ‹ÌÌˆÌÍœaÌ¸Ì—Ì©Ì¯Ì³ÌÍˆÌ°Ì…Í’Ì‚ÌÍ›Ì½Ì“Í‘ÌˆÌÌ¾Í… Ì·Ì¢ÍÍÌ³Ì–Ì¤Ì¥ÌœÌ€Ì‘ÌˆÌÌˆÌrÌ´Ì¦ÍŒÍ›Í˜oÌ´Ì©Ì©Ì¯Ì¤ÌÌŠÍ—Ì¿Ì‰Í—Í‚Í‚Ì†ÌˆÌÍ˜sÌ¶Í”Ì¼ÌÌ±Ì»Ì­Ì»Í‘Ì”Í›Ì”á¸™Ì¸Ì¢Ì€ÌÍ—Ì“ÍŠÌˆÌŠÌ‰ÌšÌšÍ Ì¸Ì Ì°ÌÌ¬ÌÌ†Ì½Ì…Ì€ÌˆÌ‚ÌŒÍ bÌ¶Ì§ÌœÌŸÍÍ”Ì˜Ì¥Í‡ÌˆÌÍ’ÌƒÍ’ÌˆÌÍŠÌ“Ì‰ÌÌ‰ÌÍ˜Í˜ÍÍÄ™ÌµÍšÌ€ÌˆÌÌ¿ÌŒÌ†ÌˆÌÍ˜Ì•Í ÍÍ…hÌ¸Ì›ÍÌ±ÍšÍ•Ì¹Ì˜Ì¥Ì Í•ÌŸÌ¼ÍÍ…Ã®Ì¶ÌÌ¹ÌºÌ°ÌÌ¿ÌŠÌ½Í’Í‘Í‘Ì½ÍnÌµÌ¢Ì¢Ì›Ì›ÌŸÍ“Ì—Ì®Ì¦ÌªÌ¥Ì©Í“ÌªÌ˜Í—Í—Ì‘ÌŠÌŒÌ‰Ì‚ÍŠÍ ÍdÌµÍÌ­Ì¤Ì²Í‹ÍŒÌƒÌÌŠ Ì·Ì§Ì§Ì›Ì¤Í‡Ì«ÌÌ—Ì»ÍšÌÌŠÌˆÌÌ‡Ì‚Í—Ì‹tÌµÍ“Ì»Ì¦Ì»Ì—Í‡ÌœÌ¼Ì»Ì«Ì¼Ì­Ì„ÌÍ˜ÌšhÌµÌ¨Ì…Ì‰Ì„eÌ¸Ì¡Ì¡Ì¨ÌÌªÌÌÌŸÍ”ÌÌÍ”Ì°Ì’Ì“Í†ÌÍ›Ì‚Ì’Í‚ÌŠÌ†Ì½ÌƒÌŒÍ˜ Ì´Ì›Ì¦Ì–Ì–Ì–Ì¹Ì–Ì¹Ì£Ì³Ì•mÌ¶Ì¡Í‰Ì¦Ì£Í‰Ì³ÌªÍ–Í•ÍÍ™ÌªÌŸÍŒÌÌÍ†ÌÌ„Ì‚ÌšÍ˜oÌ¸Ì­Ì¯Ì Ì­ÍÌ–ÍÍ—ÌÌ‰Í‹Ì…ÍŠÌ“Ì“Ì‚ÌÌ“ÌÌÍÇ«Ì´Í–ÍˆÌ–Ì£Ì¤ÍÌÌ©Ì³ÌªÌ”Í‚Ì‹Ì„Ì‘ÌÌ’ÌÌÌˆÌÃ±Ì¸Ì™ÌªÍ‰Í“Ì¼Ì¯Ì©Í‹Ì‹ÌŒÌÌƒÍ˜Ì•Í˜.ÌµÌ™Ì®Ì¾ÌÍ Í…` + `ğŸ‘»`\n\n[1] 15\n\n\nUnsurprisingly, if you try this without the backticks, you will get an error:\n\nğŸ‘» &lt;- 5\n\nError: &lt;text&gt;:1:1: unexpected invalid token\n1: ğŸ‘»\n    ^\n\n\nDo not take advantage of backticks to use names like this.\nWhy am I even telling you about backticks? They often appear in practice as a result of importing data from a spreadsheet. Usually they appear because the column names in the spreadsheet have spaces in them. One of the first things to do when tidying up data loading from a spreadsheet is to change the names.\n\n\n1.3.3 Exercises\n\nWhat is the output of 5:10?\n\n c(5, 10) [1]  5  6  7  8  9 10 [1]  5  6  7  8  9\n\nWhat is the output of 10 * c(1, 2)?\n\n [1] 10 20 [1]  30 Error in 10 * c(1, 2) : non-numeric argument to binary operator\n\nWhat is the output of c(3, 4, 6, 2)[2]?\n\n [1] 4 [1] 3 4 6 2\n\nLook at the variable names in the following list. Some of them are very bad names for stylistic reasons, but will they be accepted by R? I.e., are they syntactically valid?\n\nnz_vowels TRUEFALSE\n_nz_vowels TRUEFALSE\nğŸ¥_vowels TRUEFALSE\n`ğŸ¥_vowels` TRUEFALSE\nTraditional languages should be taught in school TRUEFALSE\nTraditional.languages_should_be.taught.in_school TRUEFALSE\nin_school TRUEFALSE\n5_points_attitude TRUEFALSE\nattitude_5 TRUEFALSE\n::::: TRUEFALSE\nfunction TRUEFALSE",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#start-an-r-script",
    "href": "getting_started.html#start-an-r-script",
    "title": "1Â  Getting Started",
    "section": "1.4 Start an R Script",
    "text": "1.4 Start an R Script\nIf we exclusively used R in the console, we would be in no better position than if we just used Excel or another spreadsheet programme. We want to be able to retrace our steps.\nIn order to start an R script go to File &gt; New File &gt; R Script or use the keyboard shortcut Cmd + Shift + N (macOS) or Ctrl + Shift + N (Windows).\nThis will open the source pane. We will now enter code in the source pane rather than the console.6\nYou can enter R code into a script in the same way you have been adding it to the console. Unlike the console, each command is saved in the script and pressing return/enter will not run the code.\nUsually you will run code by selecting it and pressing Cmd + Return (macOS) or Ctrl + Enter (Windows).7 If you have no code selected, this command will run the line which your cursor is on. The alternative is to run the entire script all at once. This can be done by pressing Source at the top right of the source pane.8\nCopy and paste the following into your new script then run it. You should see the output in the console pane.\n\n\n\n\n\n\nNote\n\n\n\nThere is some wisdom to the idea that you should get coding â€˜into your fingersâ€™ by typing out examples yourself. This may be true, but it is up to you! I have enabled the â€˜copy/pasteâ€™ button in all code blocks. You should see a clipboard icon when you have your cursor over a code block. Click the clipboard to copy the code.\n\n\n\nmy_cool_vector &lt;- c(6, 9, 4, 5, 2, 2)\nmy_cool_vector ^ 2\n\n[1] 36 81 16 25  4  4\n\n\n\n\n\nThe source pane with our script entered. Note the â€˜Sourceâ€™ button at the right.\n\n\nIt is important to leave comments, so that your code can be interpreted by other researchers (including yourself in the future!). Anything which appears after a # is a comment and will be ignored by R.\nWe could change our script as follows, and the result will be identical:\n\nmy_cool_vector &lt;- c(6, 9, 4, 5, 2, 2)\n# Square each element of my cool vector and output to console.\nmy_cool_vector ^ 2\n\n[1] 36 81 16 25  4  4\n\n\nIn actual data analysis projects, commenting is vital. Weâ€™ll see some more useful examples of commenting as we go on.\n\n1.4.1 Matrices and Dataframes\nIn data analysis we want to find associations between multiple variables. So single vectors arenâ€™t going to cut it. We need collections of vectors.\nThe simplest version of this is a matrix. Matricies are like vectors in that they can only contain elements of the same type.\nAdd the following lines to your script and run them:\n\nmy_cool_matrix &lt;- matrix(my_cool_vector, nrow = 3)\nmy_cool_matrix\n\n     [,1] [,2]\n[1,]    6    5\n[2,]    9    2\n[3,]    4    2\n\n\nWe now have a \\(3\\times2\\) matrix of numbers.\nSquare brackets are again used to manipulate individual elements. But we now have to include both rows and columns. If we want the second column and third row we can use my_cool_matrix[3, 2]. If you want the entire second column you would enter my_cool_matrix[, 2]. If you want the entire first row, you would enter my_cool_matrix[1, ]. Try out these commands in either the script or the console window.\nHave a look in the environment pane. You should now see a separation between â€œdataâ€ and â€œvaluesâ€. The â€œdataâ€ section contains structured objects, such as matrices. The one practical difference here is that if you click on something in the data section it will usually open in a new tab. In this case, youâ€™ll see something that looks a lot like a spreadsheet application.\nOften our data will include elements of multiple different types. For instance, it might include numbers indicating the age of a participant, or which of a series of options they chose. It might also include words (strings) indicating which experimental condition they are in, or a transcript of an interview. Matricies canâ€™t handle this, but data frames can.\nWe create data frames using the data.frame function. Enter the following into your script and run it:\n\n# Re-enter the vector to revert modifications made above.\nmy_cool_vector &lt;- c(6, 9, 4, 5, 2, 2)\n\nmy_data_frame &lt;- data.frame(\n  \"numbers\" = my_cool_vector,\n  \"letters\" = c(\"N\", \"Z\", \"I\", \"L\", \"B\", \"B\")\n)\n\nmy_data_frame\n\n  numbers letters\n1       6       N\n2       9       Z\n3       4       I\n4       5       L\n5       2       B\n6       2       B\n\n\nWe now have a data frame with a column of numbers and a column of corresponding letters. We have also given each of these columns a name ( â€˜numbersâ€™ for the column of numbers and â€˜lettersâ€™ for the column of letters). Each row of the data frame is an observation, and each column is a variable.9 Perhaps you can figure out what the association between the two variables is.\nWhen we have names for columns, we can access the column using the name by means of the $ symbol:\n\nmy_data_frame$numbers\n\n[1] 6 9 4 5 2 2\n\n\nNote the use of a comment to explain why we are re-creating my_cool_vector. This is the kind of step in the middle of a script which is likely to cause confusion without a comment.\n\n\n1.4.2 Functions and Help\nWe have now seen a few functions (matrix to create a matrix, and data.frame to create a data frame). Functions are what we use to perform data analysis tasks in R. To apply a function, we writes its name and then enter a series of arguments inside brackets. The arguments are the information which we pass for the function in order for it to do its work.\nRecall the matrix code from above:\n\nmy_cool_matrix &lt;- matrix(my_cool_vector, nrow = 3)\n\nHere the matrix function is given two arguments. The first is the vector my_cool_vector and the second is nrow = 3. The two arguments are separated by a comma. If we want to work out where these came from, we need to look at the help page for the function. To do that enter the following in either the script or the console:\n\n?matrix\n\nYou should now see the help screen in the output pane (bottom right). This help page tells you about three related functions. In the â€˜usageâ€™ section, you will see some code examples which use the functions. The section arguments tells you what you can include as an argument to the function. So, for instance, you see that the nrow argument expects you to tell it how many rows you want the matrix to have.\nThe functions come in the order they appear in the usage example. In this case, each of the possible arguments is named. So, for instance, the first argument is called data. We did not enter this explicitly when we used the argument. But we could have:\n\nmy_cool_matrix &lt;- matrix(data = my_cool_vector, nrow = 3)\n\nSometimes it makes your code more clear to include a name, like this.\nThe help screen also shows the default values for these argument. If there are default values, then you donâ€™t need to manually enter every argument. If you are modifying only one argument, which appears latter in the list, then you will need to use the name.\nFor instance, if we wanted to say the matrix has two columns (rather than three rows), we would have to add ncol:\n\nmy_cool_matrix &lt;- matrix(my_cool_vector, ncol = 3)\nmy_cool_matrix\n\n     [,1] [,2] [,3]\n[1,]    6    4    2\n[2,]    9    5    2\n\n\nIf we didnâ€™t, R would not know what argument we intended to modify. If you look in the â€˜detailsâ€™ section of the help page, you will see that if we only specify a number of rows or a number of columns, it will attempt to work out the other value.\n\n\n1.4.3 Install and Use a Package\nOne of the great advantages of R is that it has a large community of developers making packages to share their code. Packages allow us to cumulatively build on each others work and to do things quickly which might otherwise take a lot of time and statistical knowledge to achieve.\nWell start with a silly package: cowsay.10 This package produces text art animals who will â€˜sayâ€™ whatever text you enter.\nTo install a package, enter the following to the console:\n\ninstall.packages('cowsay')\n\nThis means that the package cowsay is now installed on your computer. To use it in a script, you need to enter the following at the top of your script:\n\nlibrary(cowsay)\n\nBy convention, we add libraries at the start of a script. This lets other researchers see exactly what is needed to run the script at the start. In addition, packages sometimes conflict with one another, and it is important to see this before we carry out any data analysis.\nTo see what functions cowsay has, look at the documentation. If you want to see the names of functions, you can enter cowsay:: and RStudio will suggest the names of functions. You can add a ? in front of any of these function names to see the help file for the function.\nThere are two functions which come with cowsay: say and endless_horse. The function we will use is called say, so enter ?say in the console.\nNow enter the following into your script:\n\nsay(\n  what = \"\", # Write your own quote here (between the quotation marks)\n  by = \"\" # Enter a 'type of thing' from the list on the help page.\n)\n\nHere, I have used comments to indicate what you need to do to complete the code.\nHereâ€™s one possible answer:\n\nsay(\n  what = \"It sure is lonely down here.\",\n  by = \"whale\"\n)\n\n\n            ------ \n           It sure is lonely down here. \n            ------ \n               \\   \n                \\  \n                 \\\n     .-'          \n'--./ /     _.---.\n'-,  (__..-`       \\\n   \\          .     |\n    `,.__.   ,__.--/\n     '._/_.'___.-`\n\n\nSometimes packages contain data. This is one day to get data in to your analysis.\nIn fact, thereâ€™s plenty of data built in to R. Often this is used to demonstrate different functions. To see these, enter data() in the console. You can load one of these datasets in to your script by entering the name of the dataset as an argument to the function data(). The following code block loads up one of these datasets.\n\ndata(warpbreaks)\n\n# This will open up an RStudio window to view that data\nView(warpbreaks)\n\nThere datasets also have help pages (see ?warpbreaks). What does this data represent?\nAs a final bit of R code, and to show you another function in action, letâ€™s plot the numeric information in warpbreaks:\n\nhist(warpbreaks$breaks)\n\n\n\n\n\n\n\n\nHere we see the distribution of the count of warp breaks while weaving for a fixed length of yarn.\n\n\n1.4.4 Exercises\n\nWhat is the output of # 2 + 2?\n\n [1] 4 2 + 2 Nothing.\n\nConsider the following code to create a matrix:\n\nmatrix(\n  data = 1:50,\n  ncol = 5\n)\n\nHow many columns does the matrix have? 105Not enough information.\nHave a look at the documentation for the function say(), are the following statements true or false:\n\nThe default argument value for by is \"cat\". TRUEFALSE\nKÄkapo is an option for the by argument. TRUEFALSE\nIf you enter what = \"catfact\" the animal will say \"catfact\". TRUEFALSE.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#modify-rstudio-defaults",
    "href": "getting_started.html#modify-rstudio-defaults",
    "title": "1Â  Getting Started",
    "section": "1.5 Modify RStudio Defaults",
    "text": "1.5 Modify RStudio Defaults\nThere are many useful options which you might want to change to improve your RStudio experience. These can be found at Tools &gt; Global Options.\nIâ€™m going to assert that you should change some settings in the â€˜Generalâ€™ window which will have appeared for you without properly explaining myself.11 Make it so that your settings match the following image:\n\n\n\nThe desired state of the General settings.\n\n\nThis means that nothing will be saved between times when you open R. This, in turn, means that your script has to contain everything that is important for your analysis and you will not accidentally rely on something being carried over between programming sessions. What do I mean? Well, you might run a piece of code and then accidentally delete it from the script. The results of running the code could hang around between sessions and you would not notice your mistake. When it comes to sharing your code, the research you share it with will not be able to run it successfully and it might take a long time to discover the problem.\n\n\n\n\n\n\nWarning\n\n\n\nIf you have been using R for a while, you may be relying on R to keep the result of long computations between sessions. If so, leave the settings as they are for now and talk to me (Josh). There are a few ways to save computations so that you do not have to, say, refit a large model from scratch every time.\n\n\nYou should also modify the appearance of RStudio to your liking using the Appearance options.\n\n\n\nThe appearance pane in General Options",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#sec-gs-additional",
    "href": "getting_started.html#sec-gs-additional",
    "title": "1Â  Getting Started",
    "section": "1.6 Additional Resources",
    "text": "1.6 Additional Resources\n\nThere are many good R and RStudio tutorials out there. One, which you can use from within RStudio is learnr. Install the package by entering install.packages('learnr') and you should see the tutorials in the environment pane.\nThe material which you get in learnr is from the book R for Data Science, available here: https://r4ds.hadley.nz/\nSee the first chapter of Winter (2019)",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#sec-alternatives",
    "href": "getting_started.html#sec-alternatives",
    "title": "1Â  Getting Started",
    "section": "1.7 Alternatives to RStudio",
    "text": "1.7 Alternatives to RStudio\nYou can write R code in any text editor which you like. Popular options with more or less integration of R include:\n\nVisual Studio Code\nESS (i.e.Â Emacs Speaks Statistics).\n\nWe wonâ€™t discuss these alternatives in these workshops. The most likely reason for you to use one of them is that you are already a keen programmer with strong preferences concerning your tools.\n\n\n\n\nWinter, Bodo. 2019. Statistics for Linguists: An Introduction Using R. New York: Routledge. https://doi.org/10.4324/9781315165547.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "getting_started.html#footnotes",
    "href": "getting_started.html#footnotes",
    "title": "1Â  Getting Started",
    "section": "",
    "text": "For alternatives which you might explore see Section 1.7â†©ï¸\nYou will find different terminology out there. Iâ€™m following the language in the official RStudio User Guide: https://docs.posit.co/ide/user/ide/guide/ui/ui-panes.html.â†©ï¸\nTry this. You should find a shortcut to open R in the Start menu on Windows or the Launchpad in macOS. On Linux or macOS you can also open a terminal window, type â€˜râ€™, and press enter.â†©ï¸\nYou might want to look at this page: https://style.tidyverse.org/. I try to follow this style guide as much as possible.â†©ï¸\nSee (https://adv-r.hadley.nz/names-values.html)â†©ï¸\nWhile you are writing, you may find it occasionally useful to use the console to double check something. But all steps required to repeat your analysis should be in a script or markdown (more about markdown later).â†©ï¸\n The same can be achieved by pressing the Run button at the top right. But since you are likely to be running code very frequently, it is best to learn the keyboard shortcut.â†©ï¸\n The keyboard shortcut for this is Cmd + Shift + S (macOS) or Ctrl + Shift + S (Windows). From now on you can look up keyboard shortcuts by using Option + Shift + K (macOS) or Alt + Shift + K (Windows).â†©ï¸\nMore on this in the next session.â†©ï¸\nI first became aware of this package through a tutorial produced by Kevin Watson for LING316.â†©ï¸\n For the rationale see: https://r4ds.hadley.nz/workflow-scripts.html.â†©ï¸",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "Introduction",
    "section": "",
    "text": "From the first semester of 2024, we will be running a series of workshops on R at NZILBB. This document will contain materials for the introductory sessions, with another collection for the more advanced sessions.\nThe focus of the workshops is on R and Open Science. The aim is to get you up to speed with the use of R and associated Open Science infrastructure so that your research is maximally reproducible, replicable, and helpful to the wider scientific community. This requires us to learn some programming!\nThis resource will gradually grow as I write up workshops. The ideal is that it will allow people to follow the material at their own pace and/or to catch up to wherever we are at in our tutorial sessions.\nFor UC students and staff, I am happy to talk over any issues you have with this material. Please get in touch with me at joshua.black@canterbury.ac.nz.\nIf you have found your way to this material by some other means, you can also email me!\n\nOther resources\nAt this stage, this is a somewhat disorganised list of texts and video which you may find interesting.\n\nThe alternative to data analysis with a programming language is usually some kind of spreadsheet. Here are some spreadsheet horror stories: https://eusprig.org/research-info/horror-stories/.\nWhy do we have to learn how to program? Why is science â€˜amateur software developmentâ€™? This is a good lecture on the topic: https://www.youtube.com/watch?v=8qzVV7eEiaI.\n\nUsually these techniques arenâ€™t explicitly taught. These workshops are our attempt to respond to this problem!\n\nWhy canâ€™t you do data science with a spreadsheet? https://www.youtube.com/watch?v=cpbtcsGE0OA\nThese workshops have been heavily influenced by Winter (2019)\n\n\n\n\n\nWinter, Bodo. 2019. Statistics for Linguists: An Introduction Using R. New York: Routledge. https://doi.org/10.4324/9781315165547."
  },
  {
    "objectID": "rstudio_server.html",
    "href": "rstudio_server.html",
    "title": "2Â  RStudio Server",
    "section": "",
    "text": "Academics at the University of Canterbury can use the RStudio Server.\nAs of this writing writingâ€¦ [details]\nCurrent details"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Brand, James, Jen Hay, Lynn Clark, Kevin Watson, and MÃ¡rton SÃ³skuthy.\n2021. â€œSystematic Co-Variation of Monophthongs Across Speakers of\nNew Zealand English.â€ Journal of Phonetics\n88: 101096. https://www.sciencedirect.com/science/article/pii/S0095447021000711.\n\n\nSÃ³skuthy, MÃ¡rton, J. Hay, and James Brand. 2019. â€œHorizontal\nDiphthong Shift in New Zealand English.â€ In. https://www.semanticscholar.org/paper/HORIZONTAL-DIPHTHONG-SHIFT-IN-NEW-ZEALAND-ENGLISH-S%C3%B3skuthy-Hay/cd1bd700686b3d1270be5536e5881e8946ba57ab.\n\n\nWieling, M. 2018. â€œAnalyzing Dynamic Phonetic Data Using\nGeneralized Additive Mixed Modeling: A Tutorial Focusing on\nArticulatory Differences Between L1 and L2\nSpeakers of English.â€ Journal of Phonetics\n70: 86â€“116. https://doi.org/10.1016/j.wocn.2018.03.002.\n\n\nWilson Black, Joshua, Jennifer Hay, Lynn Clark, and James Brand. 2023.\nâ€œThe Overlooked Effect of Amplitude on Within-Speaker Vowel\nVariation.â€ Linguistics Vanguard 9 (1): 173â€“89. https://doi.org/10.1515/lingvan-2022-0086.\n\n\nWinter, Bodo. 2019. Statistics for Linguists: An\nIntroduction Using R. New York: Routledge. https://doi.org/10.4324/9781315165547.",
    "crumbs": [
      "References"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "NZILBB R and Open Science Workshops",
    "section": "",
    "text": "Preface\nThis â€˜bookâ€™ will slowly evolve and add contributors as the NZILBB R and Open Science workshops develop. The hope is that this resource will allow people to study at their own pace."
  },
  {
    "objectID": "qualtrics.html",
    "href": "qualtrics.html",
    "title": "3Â  Loading Data from Qualtrics",
    "section": "",
    "text": "Note\n\n\n\nThis section has been written to feed in to LING615 - World Englishes and takes advantage of material prepared for LING310.\n\n\nTo interact with data from Qualtrics, we will use the package qualtRics.\nIf you havenâ€™t installed the package, run install.packages('qualtRics').\n\n\n\n\n\n\nNote\n\n\n\nThis book will have details about creating an R project soon. For now, follow the checklist below and if you want more detail see https://r4ds.had.co.nz/workflow-projects.html.\n\n\nTo set up a new R project:\n\nGo to File &gt; New Project\nSelect â€˜New Directoryâ€™ and then â€˜New Projectâ€™\nUse the browse choose a directory for the project (you might have to create a new one). For instance, Documents/linguistics_projects/ then enter a name for the project directory in the Directory name box.\nPress Create Project.\nCreate two directories in the project directory:\n\ndata\nscripts\n\n\nWe will look at how to load data from csv files generated by Qualtrics.\nPlace the csv you want to use in the data directory. For this exercise we will use this csv.\nCreate an R script and save it in the scripts directory.\nWe can now use the read_survey function from the qualtRics package to read in the data.\n\n# load the qualtRics package\nlibrary(qualtRics)\n\n# Read in the data. Our file names start from the project directory, so we \n# just say 'data/...' rather than giving the full path.\nsurvey &lt;- read_survey(file_name = 'data/Ling310-Week1-2022.csv') \n\n\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ncols(\n  .default = col_character(),\n  Progress = col_double(),\n  `Duration (in seconds)` = col_double(),\n  Finished = col_logical(),\n  RecipientLastName = col_logical(),\n  RecipientFirstName = col_logical(),\n  RecipientEmail = col_logical(),\n  ExternalReference = col_logical(),\n  LocationLatitude = col_double(),\n  LocationLongitude = col_double()\n)\nâ„¹ Use `spec()` for the full column specifications.\n\n\nThe output tells us how the columns have been interpreted. We see that the default is to assume that each column has text in it (see .default = col_character()). The exceptions to this are the progress, duration, and latitude and longitude columns which contain numbers (col_double()) and the finished, name and email columns which contain TRUE or FALSE. This makes sense for the column called Finished, but not for names and emails. Weâ€™d better check what is in those columns.\n\n# This is a base R approach (if this doesn't mean anything to you, ignore!)\n\n# Look at the summary information...\nsummary(\n  # ...about the subset of...\n  subset(\n    # ...the survey data...\n    survey, \n    # ...consisting of the following columns.\n    select = c('RecipientLastName', 'RecipientFirstName', 'RecipientEmail')\n  )\n)\n\n RecipientLastName RecipientFirstName RecipientEmail\n Mode:logical      Mode:logical       Mode:logical  \n NA's:17           NA's:17            NA's:17       \n\n\nAll 17 rows of the data are NA. That is, there is no data in these columns. You can double check that this is right by looking at the csv file in a spreadsheet programme. There is no serious problem from reading these empty columns as â€˜logicalâ€™ columns.\nWhat is actually in this data? Letâ€™s look at the first few entries.\n\nsurvey\n\n# A tibble: 17 Ã— 40\n   StartDate       EndDate Progress Duration (in secondsâ€¦Â¹ Finished RecordedDate\n   &lt;chr&gt;           &lt;chr&gt;      &lt;dbl&gt;                  &lt;dbl&gt; &lt;lgl&gt;    &lt;chr&gt;       \n 1 18/07/2022 1:27 18/07/â€¦      100                    339 TRUE     18/07/2022 â€¦\n 2 19/07/2022 0:13 19/07/â€¦      100                    570 TRUE     19/07/2022 â€¦\n 3 19/07/2022 0:35 19/07/â€¦      100                    251 TRUE     19/07/2022 â€¦\n 4 19/07/2022 20:â€¦ 19/07/â€¦      100                    277 TRUE     19/07/2022 â€¦\n 5 19/07/2022 21:â€¦ 19/07/â€¦      100                    265 TRUE     19/07/2022 â€¦\n 6 20/07/2022 20:â€¦ 20/07/â€¦      100                    343 TRUE     20/07/2022 â€¦\n 7 20/07/2022 21:â€¦ 20/07/â€¦      100                    390 TRUE     20/07/2022 â€¦\n 8 20/07/2022 21:â€¦ 20/07/â€¦      100                    328 TRUE     20/07/2022 â€¦\n 9 21/07/2022 1:58 21/07/â€¦      100                    213 TRUE     21/07/2022 â€¦\n10 21/07/2022 17:â€¦ 21/07/â€¦      100                    177 TRUE     21/07/2022 â€¦\n11 21/07/2022 19:â€¦ 21/07/â€¦      100                    497 TRUE     21/07/2022 â€¦\n12 21/07/2022 19:â€¦ 21/07/â€¦      100                    213 TRUE     21/07/2022 â€¦\n13 21/07/2022 20:â€¦ 21/07/â€¦      100                    203 TRUE     21/07/2022 â€¦\n14 22/07/2022 22:â€¦ 22/07/â€¦      100                    280 TRUE     22/07/2022 â€¦\n15 24/07/2022 21:â€¦ 24/07/â€¦      100                    639 TRUE     24/07/2022 â€¦\n16 25/07/2022 19:â€¦ 25/07/â€¦      100                     91 TRUE     25/07/2022 â€¦\n17 28/07/2022 20:â€¦ 28/07/â€¦      100                    159 TRUE     28/07/2022 â€¦\n# â„¹ abbreviated name: Â¹â€‹`Duration (in seconds)`\n# â„¹ 34 more variables: ResponseId &lt;chr&gt;, RecipientLastName &lt;lgl&gt;,\n#   RecipientFirstName &lt;lgl&gt;, RecipientEmail &lt;lgl&gt;, ExternalReference &lt;lgl&gt;,\n#   LocationLatitude &lt;dbl&gt;, LocationLongitude &lt;dbl&gt;, DistributionChannel &lt;chr&gt;,\n#   UserLanguage &lt;chr&gt;, Q3 &lt;chr&gt;, Q4 &lt;chr&gt;, Q5 &lt;chr&gt;, Q6 &lt;chr&gt;, Q8 &lt;chr&gt;,\n#   Q9 &lt;chr&gt;, Q10 &lt;chr&gt;, Q11 &lt;chr&gt;, Q12 &lt;chr&gt;, Q13 &lt;chr&gt;, Q14 &lt;chr&gt;, Q15 &lt;chr&gt;,\n#   Q16 &lt;chr&gt;, Q17 &lt;chr&gt;, Q18 &lt;chr&gt;, Q19 &lt;chr&gt;, Q20 &lt;chr&gt;, Q21 &lt;chr&gt;, â€¦"
  },
  {
    "objectID": "qualtrics.html#set-up-an-r-project",
    "href": "qualtrics.html#set-up-an-r-project",
    "title": "3Â  Loading Data from Qualtrics",
    "section": "3.1 Set up an R Project",
    "text": "3.1 Set up an R Project\nTo set up a new R project:\n\nGo to File &gt; New Project\nSelect â€˜New Directoryâ€™ and then â€˜New Projectâ€™\nUse the browse choose a directory for the project (you might have to create a new one). For instance, Documents/linguistics_projects/ then enter a name for the project directory in the Directory name box.\nPress Create Project.\nCreate two directories in the project directory:\n\ndata\nscripts\n\n\nWe will look at how to load data from csv files generated by Qualtrics.\nPlace the csv you want to use in the data directory. For this exercise we will use this csv.\nCreate an R script and save it in the scripts directory."
  },
  {
    "objectID": "qualtrics.html#load-data-exported-from-qualtrics-with-read_survey",
    "href": "qualtrics.html#load-data-exported-from-qualtrics-with-read_survey",
    "title": "3Â  Loading Data from Qualtrics",
    "section": "3.2 Load Data Exported from Qualtrics with read_survey()",
    "text": "3.2 Load Data Exported from Qualtrics with read_survey()\nWe can now use the read_survey function from the qualtRics package to read in the data.\n\n# load the qualtRics package\nlibrary(qualtRics)\n\n# Read in the data. Our file names start from the project directory, so we \n# just say 'data/...' rather than giving the full path.\nsurvey &lt;- read_survey(file_name = 'data/Ling310-Week1-2022.csv') \n\n\nâ”€â”€ Column specification â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\ncols(\n  .default = col_character(),\n  Progress = col_double(),\n  `Duration (in seconds)` = col_double(),\n  Finished = col_logical(),\n  RecipientLastName = col_logical(),\n  RecipientFirstName = col_logical(),\n  RecipientEmail = col_logical(),\n  ExternalReference = col_logical(),\n  LocationLatitude = col_double(),\n  LocationLongitude = col_double()\n)\nâ„¹ Use `spec()` for the full column specifications.\n\n\nThe output tells us how the columns have been interpreted. We see that the default is to assume that each column has text in it (see .default = col_character()). The exceptions to this are the progress, duration, and latitude and longitude columns which contain numbers (col_double()) and the finished, name and email columns which contain TRUE or FALSE. This makes sense for the column called Finished, but not for names and emails. Weâ€™d better check what is in those columns.\n\n# This is a base R approach (if this doesn't mean anything to you, ignore!)\n\n# Look at the summary information...\nsummary(\n  # ...about the subset of...\n  subset(\n    # ...the survey data...\n    survey, \n    # ...consisting of the following columns.\n    select = c('RecipientLastName', 'RecipientFirstName', 'RecipientEmail')\n  )\n)\n\n RecipientLastName RecipientFirstName RecipientEmail\n Mode:logical      Mode:logical       Mode:logical  \n NA's:17           NA's:17            NA's:17       \n\n\nAll 17 rows of the data are NA. That is, there is no data in these columns. You can double check that this is right by looking at the csv file in a spreadsheet programme. There is no serious problem from reading these empty columns as â€˜logicalâ€™ columns. Some problems are not worth dealing with!\nWhat is actually in this data? Letâ€™s look at the first few entries.\n\nsurvey\n\n# A tibble: 17 Ã— 40\n   StartDate       EndDate Progress Duration (in secondsâ€¦Â¹ Finished RecordedDate\n   &lt;chr&gt;           &lt;chr&gt;      &lt;dbl&gt;                  &lt;dbl&gt; &lt;lgl&gt;    &lt;chr&gt;       \n 1 18/07/2022 1:27 18/07/â€¦      100                    339 TRUE     18/07/2022 â€¦\n 2 19/07/2022 0:13 19/07/â€¦      100                    570 TRUE     19/07/2022 â€¦\n 3 19/07/2022 0:35 19/07/â€¦      100                    251 TRUE     19/07/2022 â€¦\n 4 19/07/2022 20:â€¦ 19/07/â€¦      100                    277 TRUE     19/07/2022 â€¦\n 5 19/07/2022 21:â€¦ 19/07/â€¦      100                    265 TRUE     19/07/2022 â€¦\n 6 20/07/2022 20:â€¦ 20/07/â€¦      100                    343 TRUE     20/07/2022 â€¦\n 7 20/07/2022 21:â€¦ 20/07/â€¦      100                    390 TRUE     20/07/2022 â€¦\n 8 20/07/2022 21:â€¦ 20/07/â€¦      100                    328 TRUE     20/07/2022 â€¦\n 9 21/07/2022 1:58 21/07/â€¦      100                    213 TRUE     21/07/2022 â€¦\n10 21/07/2022 17:â€¦ 21/07/â€¦      100                    177 TRUE     21/07/2022 â€¦\n11 21/07/2022 19:â€¦ 21/07/â€¦      100                    497 TRUE     21/07/2022 â€¦\n12 21/07/2022 19:â€¦ 21/07/â€¦      100                    213 TRUE     21/07/2022 â€¦\n13 21/07/2022 20:â€¦ 21/07/â€¦      100                    203 TRUE     21/07/2022 â€¦\n14 22/07/2022 22:â€¦ 22/07/â€¦      100                    280 TRUE     22/07/2022 â€¦\n15 24/07/2022 21:â€¦ 24/07/â€¦      100                    639 TRUE     24/07/2022 â€¦\n16 25/07/2022 19:â€¦ 25/07/â€¦      100                     91 TRUE     25/07/2022 â€¦\n17 28/07/2022 20:â€¦ 28/07/â€¦      100                    159 TRUE     28/07/2022 â€¦\n# â„¹ abbreviated name: Â¹â€‹`Duration (in seconds)`\n# â„¹ 34 more variables: ResponseId &lt;chr&gt;, RecipientLastName &lt;lgl&gt;,\n#   RecipientFirstName &lt;lgl&gt;, RecipientEmail &lt;lgl&gt;, ExternalReference &lt;lgl&gt;,\n#   LocationLatitude &lt;dbl&gt;, LocationLongitude &lt;dbl&gt;, DistributionChannel &lt;chr&gt;,\n#   UserLanguage &lt;chr&gt;, Q3 &lt;chr&gt;, Q4 &lt;chr&gt;, Q5 &lt;chr&gt;, Q6 &lt;chr&gt;, Q8 &lt;chr&gt;,\n#   Q9 &lt;chr&gt;, Q10 &lt;chr&gt;, Q11 &lt;chr&gt;, Q12 &lt;chr&gt;, Q13 &lt;chr&gt;, Q14 &lt;chr&gt;, Q15 &lt;chr&gt;,\n#   Q16 &lt;chr&gt;, Q17 &lt;chr&gt;, Q18 &lt;chr&gt;, Q19 &lt;chr&gt;, Q20 &lt;chr&gt;, Q21 &lt;chr&gt;, â€¦\n\n\nThis doesnâ€™t tell us much, because there are so many columns. How many? Look at the top left of the output: there are 17 rows and 40 columns (17 x 40). We see when the participant started and ended the survey, how far through they got (Progress), how long it took (`Duration (in seconds)`), and whether the participant finished (Finished).\nHave a look at the full data set in RStudioâ€™s viewer by either clicking on the name survey in the environment pane (top right) or entering View(survey) in the console. There are a series of columns, one for each question. When we view in the RStudio viewer we see the text of the question as â€˜labelsâ€™ underneath the actual variable name (e.g.Â the variable named Q23 has the label â€˜Does â€œpoolâ€ rhyme with â€œfoodâ€?â€™).\nThe other way to get at these labels is to use the function sjlabelled::get_label(). This will output the text label for each variable.\n\nsjlabelled::get_label(survey)\n\n                                                                                        StartDate \n                                                                                     \"Start Date\" \n                                                                                          EndDate \n                                                                                       \"End Date\" \n                                                                                         Progress \n                                                                                       \"Progress\" \n                                                                            Duration (in seconds) \n                                                                          \"Duration (in seconds)\" \n                                                                                         Finished \n                                                                                       \"Finished\" \n                                                                                     RecordedDate \n                                                                                  \"Recorded Date\" \n                                                                                       ResponseId \n                                                                                    \"Response ID\" \n                                                                                RecipientLastName \n                                                                            \"Recipient Last Name\" \n                                                                               RecipientFirstName \n                                                                           \"Recipient First Name\" \n                                                                                   RecipientEmail \n                                                                                \"Recipient Email\" \n                                                                                ExternalReference \n                                                                        \"External Data Reference\" \n                                                                                 LocationLatitude \n                                                                              \"Location Latitude\" \n                                                                                LocationLongitude \n                                                                             \"Location Longitude\" \n                                                                              DistributionChannel \n                                                                           \"Distribution Channel\" \n                                                                                     UserLanguage \n                                                                                  \"User Language\" \n                                                                                               Q3 \n                                                            \"What is/are your native language(s)\" \n                                                                                               Q4 \n                                                       \"What dialect(s) of English do you speak?\" \n                                                                                               Q5 \n                                                      \"Do Ellen and Allen sound the same to you?\" \n                                                                                               Q6 \n                                                          \"Do Air and Ear sound the same to you?\" \n                                                                                               Q8 \n\"Put your hand in front of your mouth and whisper â€˜matterâ€™.  Do you feel a distinct puff of air?\" \n                                                                                               Q9 \n                                              \"Do you pronounce an â€˜râ€™ sound in the word â€˜workâ€™?\" \n                                                                                              Q10 \n       \"Whisper â€˜the appleâ€™ to yourself?  Does the sound at the end of â€˜theâ€™ rhyme with\\nâ€˜treeâ€™?\" \n                                                                                              Q11 \n    \"Is this a sentence you could say in your variety of English?  â€œI think thereâ€™s a open doorâ€\" \n                                                                                              Q12 \n                             \"Is this a sentence you could say?  â€œthereâ€™s five dogs in the parkâ€\" \n                                                                                              Q13 \n                                    \"Is this a sentence you could say? â€œthere are many problemsâ€\" \n                                                                                              Q14 \n                             \"Say 'more or less' \\nDo you pronounce an â€˜râ€™ at the end of â€˜moreâ€™?\" \n                                                                                              Q15 \n                             \"Say 'I saw a cat\\\".   Do you pronounce an â€˜râ€™ at the end of â€˜sawâ€™?\" \n                                                                                              Q16 \n                                     \"Is this a sentence you could say?  â€œthe car needs washedâ€.\" \n                                                                                              Q17 \n                                                \"Say â€˜seesawingâ€™.  Does it contain an â€˜râ€™ sound?\" \n                                                                                              Q18 \n                                                                              \"'Bach' or 'Crib'?\" \n                                                                                              Q19 \n                                      \"Which of these is the name of the childhood chasing game?\" \n                                                                                              Q20 \n                                                           \"How do you say 'apple' in Pig Latin?\" \n                                                                                              Q21 \n                                                        \"How many syllables in the word 'grown'?\" \n                                                                                              Q22 \n                                                                \"Does 'pear' rhyme with 'share'?\" \n                                                                                              Q23 \n                                                             \"Does \\\"pool\\\" rhyme with \\\"food\\\"?\" \n                                                                                              Q24 \n                                                     \"Are 'doll' and 'dole' pronounced the same?\" \n                                                                                              Q25 \n                        \"Do you think Aucklanders sound different from people from Christchurch?\" \n                                                                                              Q26 \n        \"Do you think you could guess whether someone is MÄori or PÄkeha from listening to them?\" \n                                                                                              Q27 \n                      \"Would it be easier to guess someone's age or job from the way they sound?\" \n                                                                                              Q28 \n                                                         \"What does the word 'worry' rhyme with?\" \n\n\nYou may need to scroll right to see the question names in the output.\nThe bit of code sjlabelled:: means that we are looking for a name which exists within the package sjlabelled. You can avoid having to enter this in by loading the library sjlabelled at the start of your script. This is entirely up to you.\n\nWhat is the label of the variable named Q25?\n\n Does 'pear' rhyme with 'share'? Do you think Aucklanders sound different from people from Christchurch? It doesn't have a label.\n\n\nLetâ€™s have a look at the answers for Q24:\n\nsurvey$Q24\n\n [1] \"No\"  \"Yes\" \"No\"  \"No\"  \"Yes\" \"Yes\" \"Yes\" \"Yes\" \"No\"  \"Yes\" \"Yes\" \"No\" \n[13] \"No\"  \"Yes\" \"No\"  \"Yes\" \"Yes\"\nattr(,\"label\")\n                                         Q24 \n\"Are 'doll' and 'dole' pronounced the same?\" \n\n\nThe responses are stored as character strings. Most respondents seem to think that â€˜dollâ€™ and â€˜doleâ€™ are pronounced the same. We donâ€™t have to count these manually. Use the following code:\n\nsummary(factor(survey$Q24))\n\n No Yes \n  7  10 \n\n\nThere are thirteen respondents who think Aucklanders and people from Christchurch sound the same and four who donâ€™t.\n\nWhat do you think the function factor is doing here? See what happens if you remove it and have a look here: https://r4ds.hadley.nz/factors.html"
  },
  {
    "objectID": "qualtrics.html#exercises",
    "href": "qualtrics.html#exercises",
    "title": "3Â  Loading Data from Qualtrics",
    "section": "3.3 Exercises",
    "text": "3.3 Exercises\n\nWhat is the label of the variable named Q25?\n\n Does 'pear' rhyme with 'share'? Do you think Aucklanders sound different from people from Christchurch? It doesn't have a label."
  },
  {
    "objectID": "qualtrics.html#data-tidying",
    "href": "qualtrics.html#data-tidying",
    "title": "3Â  Loading Data from Qualtrics",
    "section": "3.3 Data Tidying",
    "text": "3.3 Data Tidying"
  },
  {
    "objectID": "qualtrics.html#a-plot",
    "href": "qualtrics.html#a-plot",
    "title": "3Â  Loading Data from Qualtrics",
    "section": "3.4 A Plot",
    "text": "3.4 A Plot"
  },
  {
    "objectID": "getting_started.html",
    "href": "getting_started.html",
    "title": "1Â  Getting Started",
    "section": "",
    "text": "1.1 Install R and RStudio\nR is a programming language. RStudio is a piece of software for interacting with R.\nYou donâ€™t have to use RStudio in order to use R, but we will assume you are using it in these workshops.1\nTo install R and RStudio on your own device follow the steps at https://posit.co/download/rstudio-desktop/.\nTo install R and RStudio on a University of Canterbury device:\nInstalling RStudio on a University of Canterbury device will also install R.",
    "crumbs": [
      "Foundations",
      "<span class='chapter-number'>1</span>Â  <span class='chapter-title'>Getting Started</span>"
    ]
  },
  {
    "objectID": "gamms_1.html",
    "href": "gamms_1.html",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "",
    "text": "4.1 Overview\nThis chapter is going to grow over three initial sessions. The rough plan is:\nWe will be using the following libraries:\n# The usual suspects\nlibrary(tidyverse)\nlibrary(here)\n\n# GAMM-specific libraries\nlibrary(mgcv)\nlibrary(itsadug)\nlibrary(gratia)\n\n# NZILBB vowel package\n# If you do not have this use the following lines of code:\n# install.packages('remotes')\n# remotes::install_github('nzilbb/nzilbb_vowels')\nlibrary(nzilbb.vowels)\n\n# Set ggplot theme\ntheme_set(theme_bw())\nThis workshop is heavily indebted to the workshops put together by MÃ¡rton SÃ³skuthy and Martijn Wieling. Links to these are provided in Section 4.5.",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  },
  {
    "objectID": "gamms_1.html#overview",
    "href": "gamms_1.html#overview",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "",
    "text": "Introduction to the idea of GAMs and how to specify parametric and smooth terms.\nThe second â€˜Mâ€™: weâ€™ll add random effects, looking at random intercepts, slopes, and smooths.\nHandling auto-correlation. How to work out when this is an issue, and the available options for solving it.",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  },
  {
    "objectID": "gamms_1.html#introduction-to-gams",
    "href": "gamms_1.html#introduction-to-gams",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "4.2 Introduction to GAMs",
    "text": "4.2 Introduction to GAMs\n\n4.2.1 Why?\nStraight lines have a lot of advantages. They can be completely specified by two numbers: how steep they are (the slope) and where they intersect the \\(y\\)-axis (the intercept). Fitting a straight line through a collection of points is just a matter of finding the optimum slope and intercept.\nBut sometimes straight lines arenâ€™t enough. There are plenty of effects in nature which do not follow a straight line. There are plenty of examples of trajectories with non-linear behaviour in the study of language. For instance, consider the following is a trajectory for the price vowel from ONZE via (SÃ³skuthy, Hay, and Brand 2019).\n\n\nTo view the code click here\n# Source: https://osf.io/74mza\n\n# Load all data (we will use the full set later)\nprice &lt;- read_rds(here('data', 'price_full.rds'))\n\n# The dataset will be explained in full below.\n# Pull out a single trajectory.\nprice &lt;- price |&gt; \n  filter(id == \"price_58\") |&gt; \n  pivot_longer(\n    cols = f1:f2,\n    names_to = \"formant_type\",\n    values_to = \"formant_value\"\n  )\n\n# Plot it\nprice_plot &lt;- price |&gt; \n  ggplot(\n    aes(\n      x = time,\n      y = formant_value,\n      colour = formant_type\n    )\n  ) +\n  geom_point() +\n  labs(\n    colour = \"Formant type\",\n    y = \"Frequency (Hz)\",\n    x = \"Time (s)\"\n  )\n\nprice_plot\n\n\n\n\n\nF1 and F2 of a PRICE vowel.\n\n\n\n\nIf we try to fit this trajectory with straight lines, we get:\n\n\nTo view the code click here\nprice_plot +\n  geom_smooth(method = \"lm\", se = FALSE)\n\n\n\n\n\nF1 and F2 of a PRICE vowel with linear model.\n\n\n\n\nWhat we want instead, is a way to fit a non-linear relationship. GA(M)Ms provide one flexible way of doing this. A simple GAM for this trajectory looks like this:\n\n\nTo view the code click here\nprice_plot +\n  geom_smooth(method = \"gam\", se = FALSE)\n\n\n\n\n\nF1 and F2 of a PRICE vowel with GAM model.\n\n\n\n\nThe same comments apply to trajectories taken from, e.g., tongue sensors or derived from video footage. They also apply at very different time scales. Consider GAMMs fit through full monologues (Wilson Black et al. 2023), or to formant values across the history of a dialect (Brand et al. 2021).\n\n\n4.2.2 What?\nWeâ€™ll start with a bit of mathematics. A linear model looks like this:\n\\[ y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\ldots + \\beta_n x_n + \\epsilon \\] where the \\(\\beta\\)â€™s are the model coefficients, the \\(x\\)â€™s are the model predictors, and the \\(\\epsilon\\) is an error term. The \\(\\beta_0\\) term is the aforementioned intercept and the other \\(\\beta_n\\)â€™s are slopes. These slopes estimate the effect of the attached predictor. For any predictor, all we get is a single slope and the intercept â€” a straight line.\nGAMs replace each of the \\(\\beta_n x_n\\) terms with a function of \\(x_n\\). This function will usually be some kind of smooth. Weâ€™ll look at this visually in a moment. But, mathematically, it looks like this:\n\\[  y = \\beta_0 + f_1(x_1) + f_2(x_2) + \\ldots + f_n(x_n) + \\epsilon .\\] The parameters have been replaces by functions. The nature of the relationship between a given predictor and \\(y\\) need not be a straight line.\nThe functions we choose attempt to balance smoothness and wiggliness. Wiggliness simply means deviation from a straight line. Smoothness indicates a lack of bumps. We are speaking intuitively, but this language is used by the mathematicians as well!.\nLetâ€™s consider one class of smooth, and how it can be used to balance these two demands: splines. Here, a set of basis functions is summed together to create a smooth line through the data.\nThe basis functions for one common set of splines looks like this ( borrowing code from Gavin Simpson):\n\n\nTo view the code click here\n# Simulate 500 observations\nset.seed(1)\nN &lt;- 500\ndata &lt;- tibble(\n  x = runif(N),\n  ytrue = map_dbl(\n    x, \n    \\(x) {x^11 * (10 * (1 - x))^6 + ((10 * (10 * x)^3) * (1 - x)^10)}\n  ),\n  ycent = ytrue - mean(ytrue),\n  yobs  = ycent + rnorm(N, sd = 0.5)\n)\nk &lt;- 10\nknots &lt;- with(data, list(x = seq(min(x), max(x), length = k)))\nsm &lt;- smoothCon(s(x, k = k, bs = \"cr\"), data = data, knots = knots)[[1]]$X\ncolnames(sm) &lt;- levs &lt;- paste0(\"f\", seq_len(k))\nbasis &lt;- pivot_longer(cbind(sm, data), -(x:yobs), names_to = 'bf')\n\nbasis |&gt; \n  ggplot(\n    aes(\n      x = x, \n      y = value, \n      colour = bf\n    )\n  ) +\n  geom_line(lwd = 2, alpha = 0.5) +\n  guides(colour = FALSE) +\n  labs(x = 'x', y = 'b(x)')\n\n\n\n\n\n\n\n\nFigureÂ 4.1: Cubic regression spline basis functions with 10 knots.\n\n\n\n\n\nEach distinct â€˜basis functionâ€™ is in a different colour. We fit out actual data by multiplying the functions by appropriate coefficients (to change how high they are on the graph) and adding them together.\nThere are a number of knots in FigureÂ 4.1. These are the points at which the functions a joined together (informally speaking) and at which we aim to ensure smoothness. For this set of basis functions, the knots are at (red points):\n\n\nTo view the code click here\n# Simulate 500 observations\nset.seed(1)\nN &lt;- 500\ndata &lt;- tibble(\n  x = runif(N),\n  ytrue = map_dbl(\n    x, \n    \\(x) {x^11 * (10 * (1 - x))^6 + ((10 * (10 * x)^3) * (1 - x)^10)}\n  ),\n  ycent = ytrue - mean(ytrue),\n  yobs  = ycent + rnorm(N, sd = 0.5)\n)\nk &lt;- 10\nknots &lt;- with(data, list(x = seq(min(x), max(x), length = k)))\nsm &lt;- smoothCon(s(x, k = k, bs = \"cr\"), data = data, knots = knots)[[1]]$X\ncolnames(sm) &lt;- levs &lt;- paste0(\"f\", seq_len(k))\nbasis &lt;- pivot_longer(cbind(sm, data), -(x:yobs), names_to = 'bf')\n\nbasis |&gt; \n  ggplot(\n    aes(\n      x = x, \n      y = value, \n      colour = bf\n    )\n  ) +\n  geom_line(lwd = 2, alpha = 0.5) +\n  geom_point(\n    inherit.aes = FALSE, \n    aes(\n      x = x\n    ),\n    y = 0,\n    colour = \"red\",\n    data = as_tibble(knots),\n    size = 5\n  ) +\n  guides(colour = FALSE) +\n  labs(x = 'x', y = 'b(x)')\n\n\n\n\n\n\n\n\nFigureÂ 4.2: Cubic regression spline basis functions with 10 knots (red dots).\n\n\n\n\n\nAgain, borrowing code from Gavin Simpson, we can see what this looks like for our simulated data.\n\n\nTo view the code click here\nbeta &lt;- coef(lm(ycent ~ sm - 1, data = data))\nwtbasis &lt;- sweep(sm, 2L, beta, FUN = \"*\")\ncolnames(wtbasis) &lt;- colnames(sm) &lt;- paste0(\"F\", seq_len(k))\n## create stacked unweighted and weighted basis\nbasis &lt;- as_tibble(wtbasis) %&gt;%\n  mutate(\n    x = data$x,\n    spline_fit = pmap_dbl(\n      # Yikes, bad coding here by me (JWB)\n      list(F1, F2, F3, F4, F5, F6, F7, F8, F9, F10),\n      sum\n    )\n  ) \n\nbasis_long &lt;- basis |&gt; \n  pivot_longer(\n    cols = contains('F'),\n    values_to = \"value\",\n    names_to = \"bf\"\n  )\n\n\ndata |&gt; \n  ggplot(\n    aes(\n      x = x,\n      y = yobs\n    )\n  ) +\n  geom_point(alpha = 0.4) +\n  geom_line(\n    aes(\n      x = x,\n      y = value,\n      colour = bf\n    ),\n    data = basis_long,\n    inherit.aes = FALSE,\n    linewidth = 1\n  ) +\n  geom_line(\n    aes(\n      x = x,\n      y = spline_fit\n    ),\n    inherit.aes = FALSE,\n    colour = \"black\",\n    linewidth = 1,\n    data = basis\n  ) + \n  guides(colour = FALSE)\n\n\n\n\n\n\n\n\nFigureÂ 4.3: Simulated data (black dots) with the basis functions after multiplication by their weights (colourful lines) and the sum of the basis functions (black line).\n\n\n\n\n\nSpend some time looking at FigureÂ 4.3. Convince yourself that if you added together the colourful lines you would get the black line. The easiest way to do this is to work one point on the \\(x\\)-axis at a time. The case where \\(x=0\\) is the easiest, where the only colourful line is the red one and it is at the same point on the \\(y\\)-axis as the black line.\nWhat about this wiggliness and smoothness trade off? Weâ€™ve already seen one way in which wiggliness can be controlled: the number of knots sets an upper limit on how wiggly the resulting smooth function can be. If we only had 3 knots, this is what we would get:\n\n\nTo view the code click here\nk &lt;- 3\nknots &lt;- with(data, list(x = seq(min(x), max(x), length = k)))\nsm &lt;- smoothCon(s(x, k = k, bs = \"cr\"), data = data, knots = knots)[[1]]$X\ncolnames(sm) &lt;- levs &lt;- paste0(\"f\", seq_len(k))\nbeta &lt;- coef(lm(ycent ~ sm - 1, data = data))\nwtbasis &lt;- sweep(sm, 2L, beta, FUN = \"*\")\ncolnames(wtbasis) &lt;- colnames(sm) &lt;- paste0(\"F\", seq_len(k))\n## create stacked unweighted and weighted basis\nbasis &lt;- as_tibble(wtbasis) %&gt;%\n  mutate(\n    x = data$x,\n    spline_fit = pmap_dbl(\n      # Yikes, bad coding here by me (JWB)\n      list(F1, F2, F3),\n      sum\n    )\n  ) \n\nbasis_long &lt;- basis |&gt; \n  pivot_longer(\n    cols = contains('F'),\n    values_to = \"value\",\n    names_to = \"bf\"\n  )\n\n\ndata |&gt; \n  ggplot(\n    aes(\n      x = x,\n      y = yobs\n    )\n  ) +\n  geom_point(alpha = 0.4) +\n  geom_line(\n    aes(\n      x = x,\n      y = value,\n      colour = bf\n    ),\n    data = basis_long,\n    inherit.aes = FALSE,\n    linewidth = 1\n  ) +\n  geom_line(\n    aes(\n      x = x,\n      y = spline_fit\n    ),\n    inherit.aes = FALSE,\n    colour = \"black\",\n    linewidth = 1,\n    data = basis\n  ) + \n  guides(colour = FALSE)\n\n\n\n\n\n\n\n\nFigureÂ 4.4: Simulated data (black dots) with the basis functions after multiplication by their weights (colourful lines) and the sum of the basis functions (black line).\n\n\n\n\n\nThe black line is our best possible fit to the data here, but it is no good. It needs to be wigglier.\nSo knots are one determinant of wiggliness. But there is another: the smoothing parameter. This is used in order to penalise wiggliness when we fit a GAM model and is handled automatically by the mgcv package. In practice, it is determined from the data, rather than being manually specified. However, it is worth looking manually at what happens if we set the smoothing parameter too low and fail to sufficiently penalise wiggliness.\nHereâ€™s what an excessively wiggly smooth function looks like with the New Zealand English dress vowel in ONZE:\n\n\nTo view the code click here\nonze_vowels_full |&gt; \n  lobanov_2() |&gt; \n  filter(\n    gender == \"F\",\n    vowel == \"DRESS\"\n  ) |&gt; \n  group_by(speaker) |&gt; \n  summarise(\n    F1_lob2 = mean(F1_lob2),\n    yob = first(yob)\n  ) |&gt; \n  ggplot(\n    aes(\n      x = yob,\n      y = F1_lob2\n    )\n  ) +\n  geom_jitter(alpha = 0.5) +\n  geom_smooth(\n    method = \"gam\", \n    formula =  y ~ s(x, bs = \"cs\", k = 50, sp=0.01), \n    se=FALSE\n  )\n\n\n\n\n\n\n\n\nFigureÂ 4.5: Mean normalised F1 for female speakers in ONZE by year of birth. Smoothing parameter set to 0.01.\n\n\n\n\n\nOn the other side, we can set the smoothing parameter too high. If we do, weâ€™ll end up with a straight line.\n\n\nTo view the code click here\nmean_onze_full &lt;- onze_vowels_full |&gt; \n  lobanov_2() |&gt; \n  filter(\n    vowel == \"DRESS\"\n  ) |&gt; \n  group_by(speaker) |&gt; \n  summarise(\n    F1_lob2 = mean(F1_lob2),\n    yob = first(yob),\n    speech_rate = mean(speech_rate),\n    gender = first(gender)\n  )\n\nmean_onze_full |&gt; \n  filter(gender == \"F\") |&gt; \n  ggplot(\n    aes(\n      x = yob,\n      y = F1_lob2\n    )\n  ) +\n  geom_jitter(alpha = 0.5) +\n  geom_smooth(\n    method = \"gam\", \n    formula =  y ~ s(x, bs = \"cs\", k = 50, sp=10000000), \n    se=FALSE\n  )\n\n\n\n\n\n\n\n\nFigureÂ 4.6: Mean normalised F1 for female speakers in ONZE by year of birth. Smoothing parameter set to 10,000,000.\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nWe are in the broad area of a core data science concept: the â€˜bias variance tradeoffâ€™. That is, with any statistical learning method, we can introduce errors with the assumptions of our model (bias) and errors due to excessively following small fluctuations in our data (variance). But the less bias we include, the more we will be lead astray by noise and vice versa. Itâ€™s a tradeoff.\nIn the case we are looking at now, reducing the smoothing parameter is equivalent to decreasing bias and increasing variance.\nSee the Wikipedia page.\n\n\n\n\n4.2.3 Fitting GAMs with mgcv\nHow do we specify GAMs with the mgcv package? Letâ€™s start with model formulae.\nThe most obvious this is the construction of smooth terms. These use the s function. Letâ€™s look at the ONZE data from FigureÂ 4.5 and FigureÂ 4.6. Here we want normalised first formant values to vary with year of birth in a non-linear way. We want a smooth on year of birth.\nWhat are the column names here?\n\nmean_onze_full\n\n# A tibble: 481 Ã— 5\n   speaker  F1_lob2   yob speech_rate gender\n   &lt;fct&gt;      &lt;dbl&gt; &lt;int&gt;       &lt;dbl&gt; &lt;fct&gt; \n 1 CC_f_007  -0.765  1982        5.76 F     \n 2 CC_f_010  -0.554  1947        5.06 F     \n 3 CC_f_020  -0.242  1936        5.04 F     \n 4 CC_f_024  -0.760  1973        5.61 F     \n 5 CC_f_025  -0.747  1949        4.63 F     \n 6 CC_f_027  -0.962  1981        5.22 F     \n 7 CC_f_033  -0.725  1953        4.82 F     \n 8 CC_f_040  -0.731  1955        4.24 F     \n 9 CC_f_051  -0.769  1955        4.67 F     \n10 CC_f_052  -0.838  1942        5.61 F     \n# â„¹ 471 more rows\n\n\nThe variable we want to explain is F1_lob2. This contains normalised mean first formant values for each speaker. We want to explain it using `yobâ€™, which we can see from the tibble output, is an integer. Weâ€™ll look at incorporating the other variables later.\nThe simplest version of the formula is this: F1_lob2 ~ s(yob). But this is usually bad practice â€” we should be more explicit! As a general principle, relying on defaults is dangerous as they can change under you, causing your code to have a different outcome.\nThe first area to be explicit is the knots. The default value for many smoothing splines is \\(10\\) and this is almost always fine. But we should think about it each time we fit a GAMM. So, an improvement: F1_lob2 ~ s(yob, k = 10).\nThe second argument to highlight is bs. This says what kind of basis functions we are using. The default, tp, or thin plate regression splines, are fine. Typically this choice wonâ€™t make a big different to you. But I will add more detail here soon. Regardless, it is good to make this explicit. So our final version of this formula: F1_lob2 ~ s(yob, k = 10, bs = \"tp\").\nWhat do we do with this formula? We will use the function bam to fit our first GAM.\n\n\n\n\n\n\nNote\n\n\n\nWe could just as easily use the gam function, but bam is optimised for large datasets.\n\n\n\nonze_fit &lt;- bam(\n  formula = F1_lob2 ~ s(yob, k = 10, bs = \"tp\"),\n  data = mean_onze_full\n)\n\nWe obtain a summary for this model using the summary function:\n\nsummary(onze_fit)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nF1_lob2 ~ s(yob, k = 10, bs = \"tp\")\n\nParametric coefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.590123   0.008102  -72.84   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n         edf Ref.df     F p-value    \ns(yob) 3.633  4.481 178.6  &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.625   Deviance explained = 62.8%\nfREML = -138.75  Scale est. = 0.031571  n = 481\n\n\nThis summary has two primary sections. The Parametric coefficients, which indicate the non-smooth aspects of the model. In this case, the model fits an intercept term, which sets the overall height of the smooth function. The Approximate significance of smooth terms section indicates, as it says, the approximate significance of our smooths. This is the GAM equivalent of the coefficient for a variable in a linear model.\nIn this model, we only have s(yob) to look at. We see that it has an edf or â€˜estimated degrees of freedomâ€™ of 3.633. This is an indication of how wiggly the line is. If the esimated degrees of freedom are 1, itâ€™s pretty much a straight line. We also see a p-value entry. This indicates whether the shape of the smooth is statistically significantly different from a flat line at the intercept value. In this case, unsurprisingly, it is distinct from a flat line.\nBut there are some problems here. First, we are merging male and female data together here. What if we want to fit a smooth for both male and female speakers? Here we can us the by argument to s() and add a parametric term for gender. This results in:\n\nonze_fit_gender &lt;- bam(\n  formula = F1_lob2 ~ gender + s(yob, by = gender, k = 10, bs = \"tp\"),\n  data = mean_onze_full\n)\n\nsummary(onze_fit_gender)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nF1_lob2 ~ gender + s(yob, by = gender, k = 10, bs = \"tp\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.64493    0.01146 -56.255  &lt; 2e-16 ***\ngenderM      0.10157    0.01565   6.492 2.13e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                 edf Ref.df      F p-value    \ns(yob):genderF 2.754  3.394  72.13  &lt;2e-16 ***\ns(yob):genderM 1.000  1.000 588.35  &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.658   Deviance explained = 66.2%\nfREML = -156.83  Scale est. = 0.028773  n = 481\n\n\nNow we have two intercept terms, one for the female speakers and one for the male, both of which are significant. Just as in generalised linear models, the genderM parametric term gives a difference from the female intercept. This indicates that the first formant value is on average higher for male speakers. In the smooth terms section we now see s(yob):genderF and s(yob):genderM. We get independent p-values for each. What we do not get is a representation of the difference between the smooth for the female speakers and the smooth for the male speakers.1\nNote that the smooth for the male speakers in effectively a straight line. We will see this in a moment when we visualise.\nWe will add one more thing to this model before turning to diagnostics and plotting. What if we want two smooths? We know that speech rate can affect formant values. We can add this as an additional smooth term as follows:\n\nonze_fit_rate &lt;- bam(\n  formula = F1_lob2 ~ gender + \n    s(yob, by = gender, k = 10, bs = \"tp\") +\n    s(speech_rate, k = 10, bs = \"tp\"),\n  data = mean_onze_full\n)\n\nsummary(onze_fit_rate)\n\n\nFamily: gaussian \nLink function: identity \n\nFormula:\nF1_lob2 ~ gender + s(yob, by = gender, k = 10, bs = \"tp\") + s(speech_rate, \n    k = 10, bs = \"tp\")\n\nParametric coefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.64505    0.01148 -56.176  &lt; 2e-16 ***\ngenderM      0.10180    0.01568   6.492 2.14e-10 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nApproximate significance of smooth terms:\n                 edf Ref.df       F p-value    \ns(yob):genderF 2.754  3.393  64.128  &lt;2e-16 ***\ns(yob):genderM 1.000  1.000 488.583  &lt;2e-16 ***\ns(speech_rate) 1.000  1.000   0.082   0.775    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nR-sq.(adj) =  0.658   Deviance explained = 66.2%\nfREML = -153.06  Scale est. = 0.028828  n = 481\n\n\nIn this case we donâ€™t see a significant difference as a result of speech rate. This may be because we are working with mean values for the formants. Once we can include random effects, and thus multiple values from a single speaker, this will change!\n\n\n\n\n\n\nTip\n\n\n\nWieling (2018) provides an example of building up a model from the ground up, exploring many different possible structures and including the R code. It is a good first port of call for looking at additional possible structures.\n\n\n\n\n4.2.4 Model diagnostics\nThe primary port of call for model diagnostics in mgcv is the gam.check() function. One of the outputs is a text output to help determine if \\(k\\) is too low.\n\ngam.check(onze_fit_rate)\n\n\nMethod: fREML   Optimizer: perf newton\nfull convergence after 15 iterations.\nGradient range [-1.027586e-06,1.027607e-07]\n(score -153.0627 & scale 0.02882816).\nHessian positive definite, eigenvalue range [2.671181e-07,238.0032].\nModel rank =  29 / 29 \n\nBasis dimension (k) checking results. Low p-value (k-index&lt;1) may\nindicate that k is too low, especially if edf is close to k'.\n\n                 k'  edf k-index p-value  \ns(yob):genderF 9.00 2.75    1.00   0.530  \ns(yob):genderM 9.00 1.00    1.00   0.460  \ns(speech_rate) 9.00 1.00    0.93   0.065 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nThe output above has an entry for each smooth term in the model. k' indicate the knots the smooth function has available. This, as explained above, is an upper limit on wiggliness. It will usually be one less than the value of k given in the model formula. The value edf indicates the actual wiggliness of the smooth. To determine if there is evidence of insufficient k, check whether the p-value is low and the edf is close to k'. If so, consider increasing k in the model. In this case, k is plenty high enough.\nLetâ€™s see a case where this doesnâ€™t work well.\n\nsim_fit &lt;- bam(\n  formula = yobs ~ s(x, k = 3, bs = \"cr\"),\n  data = data\n)\n\ngam.check(sim_fit)\n\n\nMethod: fREML   Optimizer: perf newton\nfull convergence after 11 iterations.\nGradient range [-2.519727e-09,2.506653e-09]\n(score 1287.688 & scale 9.969049).\nHessian positive definite, eigenvalue range [0.4972726,249.001].\nModel rank =  3 / 3 \n\nBasis dimension (k) checking results. Low p-value (k-index&lt;1) may\nindicate that k is too low, especially if edf is close to k'.\n\n     k' edf k-index p-value    \ns(x)  2   2    0.03  &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nHere k' and edf are the same, and the p-value is very low. Something is going wrong here. In fact, the problem here is the same problem we saw in FigureÂ 4.4.\nIf you run gam.check you will also see some diagnostic plots. I have suppressed them in this document. The gratia package provides a nice wrapper for the gam.check visualisations (via the appraise function). It has the advantage of being a single plot in ggplot format which will take on any global changes to you â€˜themeâ€™. That is, it will produce output which matches your other plots.\nLetâ€™s look at the bad fit to our simulated data again:\n\nappraise(sim_fit)\n\n\n\n\n\n\n\n\nThese plots tell us something about the residuals. The assumption of our model is that these residuals will be normally distributed. That is, we assume that the variation which is left behind by our model looks like random observations from a normal distribution.\nThese diagnostic plots are not like this. At the top left, we should see a straight line of black points following the red line. However, we see that at the tails, at extreme values of a predictor, we are not getting what we would expect from a normal distribution. The histogram tells a similar story. This should look like a nice(ish) bell curve. But the most extreme warning signs are the two plots on the right. These show the model predictions plotted against the actual values. There should be no obvious (non-linear) pattern in these plots.\nWe already know what to do in this case, we need to increase \\(k\\)! If we do, this is what we get:\n\nsim_fit_highk &lt;- bam(\n  formula = yobs ~ s(x, k = 20, bs = \"cr\"),\n  data = data\n)\n\nappraise(sim_fit_highk)  \n\n\n\n\n\n\n\n\nMuch better! And the check of k looks OK too:\n\ngam.check(sim_fit_highk)\n\n\nMethod: fREML   Optimizer: perf newton\nfull convergence after 5 iterations.\nGradient range [-1.018439e-06,1.032479e-06]\n(score 434.2567 & scale 0.2813964).\nHessian positive definite, eigenvalue range [8.433327,249.2893].\nModel rank =  20 / 20 \n\nBasis dimension (k) checking results. Low p-value (k-index&lt;1) may\nindicate that k is too low, especially if edf is close to k'.\n\n       k'  edf k-index p-value\ns(x) 19.0 17.7     1.1    0.98\n\n\nReturning to our model of the ONZE data, letâ€™s use appraise again:\n\nappraise(onze_fit_rate)\n\n\n\n\n\n\n\n\nThis looks basically fine. But we can see heavier tails that we would usually want at either end of the QQ plot and the histogram. This is quite common in vocalic data. One way to handle this is to assume that the residuals follow a t distribution instead (these have fatter tails than normal distributions). We can do this with the family argument to bam. If we do this, the plots look a bit better:\n\nonze_fit_rate &lt;- bam(\n  formula = F1_lob2 ~ gender + \n    s(yob, by = gender, k = 10, bs = \"tp\") +\n    s(speech_rate, k = 10, bs = \"tp\"),\n  data = mean_onze_full,\n  family = scat(link=\"identity\")\n)\n\nappraise(onze_fit_rate)\n\n\n\n\n\n\n\n\nWe will see a case below where a t-distribution functions better than a standard normal distribution with formant data. It is worth checking this case-by-case though.\n\n\n4.2.5 Plotting\nPlotting smooths can be done in at least three ways:\n\nUsing a prediction function to generate predictions from the model and then plot them yourself. The advantage is high flexibility in your plots.\nUse the plot_smooth() and related functions from itsadug.\nUse the GAM plotting functions from gratia.\n\nLetâ€™s look at the plot_smooth() function. This has been used in a lot of projects at NZILBB.\n\nplot_smooth(\n  x = # the model,\n  view = # the name of the variable you want to plot.\n  cond = # a named list containing the values of other terms in the model. \n  # if not given you will get mean values.\n  plot_all = # The name of any factors which for which you want all levels to be\n  # plotted\n  rug = # display a 'rug' at the bottom of the plot to indicate where there are\n  # actual observations.\n)\n\nNow, using these to plot the ONZE model, we get:\n\nplot_smooth(\n  x = onze_fit_rate,\n  view = \"yob\",\n  plot_all = \"gender\",\n  rug = TRUE\n)\n\nSummary:\n    * gender : factor; set to the value(s): F, M. \n    * yob : numeric predictor; with 30 values ranging from 1864.000000 to 1982.000000. \n    * speech_rate : numeric predictor; set to the value(s): 4.86001666666667. \n    * NOTE : No random effects in the model to cancel.\n \n\n\n\n\n\n\n\n\n\nNote that the values given for other predictors are given in console output.\nNow change the view and cond arguments and see what happens.",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  },
  {
    "objectID": "gamms_1.html#the-second-m-mixed-effects",
    "href": "gamms_1.html#the-second-m-mixed-effects",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "4.3 The Second â€˜Mâ€™: Mixed Effects",
    "text": "4.3 The Second â€˜Mâ€™: Mixed Effects",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  },
  {
    "objectID": "gamms_1.html#auto-correlation",
    "href": "gamms_1.html#auto-correlation",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "4.4 Auto-correlation",
    "text": "4.4 Auto-correlation",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  },
  {
    "objectID": "gamms_1.html#sec-resources",
    "href": "gamms_1.html#sec-resources",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "4.5 Further Resources",
    "text": "4.5 Further Resources\n\nMÃ¡rton SÃ³skuthyâ€™s GAMM tutorial: https://arxiv.org/pdf/1703.05339.pdf\nMÃ¡rton SÃ³skuthyâ€™s paper compared multiple significance testing strategies for error rates: https://www.sciencedirect.com/science/article/pii/S009544702030108X#s0070\nMartijn Wielingâ€™s tutorial: https://www.sciencedirect.com/science/article/pii/S0095447017301377\n\n\n\n\n\n\n\nNote\n\n\n\nResources have also been written by non-Martins. I will add some soon!\n\n\n\n\n\n\nBrand, James, Jen Hay, Lynn Clark, Kevin Watson, and MÃ¡rton SÃ³skuthy. 2021. â€œSystematic Co-Variation of Monophthongs Across Speakers of New Zealand English.â€ Journal of Phonetics 88: 101096. https://www.sciencedirect.com/science/article/pii/S0095447021000711.\n\n\nSÃ³skuthy, MÃ¡rton, J. Hay, and James Brand. 2019. â€œHorizontal Diphthong Shift in New Zealand English.â€ In. https://www.semanticscholar.org/paper/HORIZONTAL-DIPHTHONG-SHIFT-IN-NEW-ZEALAND-ENGLISH-S%C3%B3skuthy-Hay/cd1bd700686b3d1270be5536e5881e8946ba57ab.\n\n\nWieling, M. 2018. â€œAnalyzing Dynamic Phonetic Data Using Generalized Additive Mixed Modeling: A Tutorial Focusing on Articulatory Differences Between L1 and L2 Speakers of English.â€ Journal of Phonetics 70: 86â€“116. https://doi.org/10.1016/j.wocn.2018.03.002.\n\n\nWilson Black, Joshua, Jennifer Hay, Lynn Clark, and James Brand. 2023. â€œThe Overlooked Effect of Amplitude on Within-Speaker Vowel Variation.â€ Linguistics Vanguard 9 (1): 173â€“89. https://doi.org/10.1515/lingvan-2022-0086.",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  },
  {
    "objectID": "gamms_1.html#mess",
    "href": "gamms_1.html#mess",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "4.6 Mess",
    "text": "4.6 Mess\n\n4.6.1 Example\nSÃ³skuthy, Hay, and Brand (2019) Use GAMMs to explore both vertical and horizontal shifts.\nIdentification of points of inflection.\n\nIn this paper, we focus on PRICE and MOUTH in contexts where they are not followed by a voiceless consonant.\n\n\nA variety of NZE which is sometimes called â€˜modiï¬ed NZEâ€™ combines advanced front vowel changes with conservative â€˜poshâ€™ diphthongs. Hay et al 2008 NZE\n\n\nA variety of NZE which is sometimes called â€˜modiï¬ed NZEâ€™ combines advanced front vowel changes with conservative â€˜poshâ€™ diphthongs. (43)\n\n\nWhen people ï¬rst commented on the NZE accent, they singled out the closing diphthongs ï­ï¯ïµï´ï¨ , ï°ï²ï©ï£ï¥ , ï¦ï¡ï£ï¥ and ï§ï¯ï¡ï´ as the most noticeable features (see Chapter 2, section 2.6.10 and Chapter 5, section 5.4). These diphthongs still play a social role within NZE. As in other varieties of English, women play a double role, leading change but also using more conservative realisations of phonemes such as the closing diphthongs that have social connotations. At the end of Chapter 2 (section 2.7) we referred to the â€˜white rabbit phenomenonâ€™ whereby such women can be careful to pronounce words like white â€˜correctlyâ€™ as [hwaet] and avoid the â€˜terribleâ€™ pronunciation of â€˜woiteâ€™. However they are often unaware of the changes to the front vowels and happily pronounce the word rabbit as â€˜rebbitâ€™ with the innovative raised ï¤ï²ï¥ï³ï³ vowel. Approximate indications of higher class (more â€˜cultivatedâ€™) and lower class (â€˜broaderâ€™) pronunciations of these four diphthongs are shown in Figure 6.1. (102)\n\n\n\n\n\nBrand, James, Jen Hay, Lynn Clark, Kevin Watson, and MÃ¡rton SÃ³skuthy. 2021. â€œSystematic Co-Variation of Monophthongs Across Speakers of New Zealand English.â€ Journal of Phonetics 88: 101096. https://www.sciencedirect.com/science/article/pii/S0095447021000711.\n\n\nSÃ³skuthy, MÃ¡rton, J. Hay, and James Brand. 2019. â€œHorizontal Diphthong Shift in New Zealand English.â€ In. https://www.semanticscholar.org/paper/HORIZONTAL-DIPHTHONG-SHIFT-IN-NEW-ZEALAND-ENGLISH-S%C3%B3skuthy-Hay/cd1bd700686b3d1270be5536e5881e8946ba57ab.\n\n\nWieling, M. 2018. â€œAnalyzing Dynamic Phonetic Data Using Generalized Additive Mixed Modeling: A Tutorial Focusing on Articulatory Differences Between L1 and L2 Speakers of English.â€ Journal of Phonetics 70: 86â€“116. https://doi.org/10.1016/j.wocn.2018.03.002.\n\n\nWilson Black, Joshua, Jennifer Hay, Lynn Clark, and James Brand. 2023. â€œThe Overlooked Effect of Amplitude on Within-Speaker Vowel Variation.â€ Linguistics Vanguard 9 (1): 173â€“89. https://doi.org/10.1515/lingvan-2022-0086.",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  },
  {
    "objectID": "gamms_1.html#footnotes",
    "href": "gamms_1.html#footnotes",
    "title": "4Â  Generalized Additive (Mixed) Models",
    "section": "",
    "text": "We will look at how to do this later in the series.â†©ï¸",
    "crumbs": [
      "Additional Topics",
      "<span class='chapter-number'>4</span>Â  <span class='chapter-title'>Generalized Additive (Mixed) Models</span>"
    ]
  }
]